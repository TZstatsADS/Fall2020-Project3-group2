{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Model for Project 3 \n",
    "### By Tianle Zhu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications import VGG16\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "import os\n",
    "from shutil import copyfile, move\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "from sklearn import metrics\n",
    "#from tensorflow.keras import optimizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2384 images belonging to 2 classes.\n",
      "Found 616 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "train_data_dir = \"../data/train_set/data/train\"\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    shuffle=True,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "validation_data_dir = \"../data/train_set/data/validation\"\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "input_shape = (64,64,3)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape = input_shape, weights = 'imagenet', include_top = False)\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
    "x = Dense(1, activation = 'sigmoid')(x)  # adding the output layer with sigmoid function \n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "# learning rate try  0.01, 0.001, 0.001\n",
    "#Adam = keras.optimizers.Adam(lr = 0.001)\n",
    "Adam = optimizers.Adam(lr = 0.05)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 18s 482ms/step - loss: 2.7634 - acc: 0.8240 - val_loss: 2.3914 - val_acc: 0.8500\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 23s 595ms/step - loss: 3.5398 - acc: 0.7780 - val_loss: 2.9892 - val_acc: 0.8125\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 21s 549ms/step - loss: 3.1727 - acc: 0.8010 - val_loss: 3.1885 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 3.0416 - acc: 0.8092 - val_loss: 2.7270 - val_acc: 0.8289\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 3.1203 - acc: 0.8043 - val_loss: 2.3914 - val_acc: 0.8500\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 21s 553ms/step - loss: 3.5398 - acc: 0.7780 - val_loss: 2.4910 - val_acc: 0.8438\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 18s 464ms/step - loss: 3.7234 - acc: 0.7664 - val_loss: 3.2881 - val_acc: 0.7937\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 3.0154 - acc: 0.8109 - val_loss: 3.4612 - val_acc: 0.7829\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 14s 376ms/step - loss: 3.1990 - acc: 0.7993 - val_loss: 3.0888 - val_acc: 0.8063\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 14s 366ms/step - loss: 2.9892 - acc: 0.8125 - val_loss: 2.3914 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "start_time_train = time.time()\n",
    "history = model.fit_generator(train_generator,\n",
    "                   steps_per_epoch = 38,  # this should be equal to total number of images in training set. Change this for better results. \n",
    "                   epochs = 10,  # change this for better results\n",
    "                   class_weight = [85,1], # change this for better results\n",
    "                   validation_data = validation_generator,\n",
    "                   validation_steps = 10)\n",
    "elapsed_time_train = time.time() - start_time_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['acc'][-1]\n",
    "validation_acc = history.history['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/38 [==============================] - 12s 305ms/step\n"
     ]
    }
   ],
   "source": [
    "start_time_test = time.time()\n",
    "pred = model.predict_generator(validation_generator,verbose = 1, steps= 616/16)\n",
    "elapsed_time_test = time.time() - start_time_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.976257020776924, 0.8133116883116883]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(validation_generator,steps = 616/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate AUC\n",
    "fpr, tpr, thresholds = metrics.roc_curve(validation_generator.classes, pred)\n",
    "AUC_vaule = metrics.auc(fpr, tpr)\n",
    "AUC_vaule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 186.29671001434326\n",
      "Testing time: 11.886746883392334\n",
      "Training Accuracy: 0.8125\n",
      "Validation Accuracy: 0.85\n",
      "AUC for VGG16 moldel: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time:\", elapsed_time_train)\n",
    "print(\"Testing time:\", elapsed_time_test)\n",
    "print(\"Training Accuracy:\", train_acc)\n",
    "print(\"Validation Accuracy:\", validation_acc)\n",
    "print(\"AUC for VGG16 moldel:\", AUC_vaule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# testing_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "# testing_data_dir = \"../data/train_set/data/test\"\n",
    "\n",
    "# testing_generator = testing_datagen.flow_from_directory(\n",
    "#     testing_data_dir,\n",
    "#     target_size=(64, 64),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
